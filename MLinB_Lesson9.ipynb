{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение в бизнесе\n",
    "\n",
    "### Урок 9. Кейс 2. Внедрение модели в продукцию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать веб-сервис на Flask через Google Colab или на локальной машине. Научиться отправлять post-запросы с помощью Postman и получать на них ответы. Можно использовать любую из обученных моделей в заданиях ко 2 и 3 занятиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Пробный запуск Flask\n",
    "\n",
    "# app = Flask(__name__)\n",
    "# run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "# @app.route(\"/a\")\n",
    "# def hello():\n",
    "#     return \"Hello World!\"\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) Client VM (build 25.241-b07, mixed mode)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\server.py:379: UserWarning:   You have a 32-bit version of Java. H2O works best with 64-bit Java.\n",
      "  Please download the latest 64-bit Java SE JDK from Oracle.\n",
      "\n",
      "  warn(\"  You have a 32-bit version of Java. H2O works best with 64-bit Java.\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting server from C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\rajul\\AppData\\Local\\Temp\\tmp6af8ozm6\n",
      "  JVM stdout: C:\\Users\\rajul\\AppData\\Local\\Temp\\tmp6af8ozm6\\h2o_rajul_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\rajul\\AppData\\Local\\Temp\\tmp6af8ozm6\\h2o_rajul_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>14 days, 1 hour and 5 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_rajul_gf7rry</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>247.5 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O cluster uptime:         06 secs\n",
       "H2O cluster timezone:       Europe/Moscow\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.3\n",
       "H2O cluster version age:    14 days, 1 hour and 5 minutes\n",
       "H2O cluster name:           H2O_from_python_rajul_gf7rry\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    247.5 Mb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем обученные модели\n",
    "\n",
    "model_glm_poisson = h2o.load_model('GLM_model_python_1581997959683_20')\n",
    "model_glm_gamma = h2o.load_model('GLM_model_python_1581997959683_21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on http://4c6bce7c.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Обработчики и запуск Flask\n",
    "\n",
    "def map_for_dict_Gender(Gender):\n",
    "  dict_Gender = {'Male':0, 'Female':1}\n",
    "  res = dict_Gender.get(Gender)\n",
    "  return res\n",
    "\n",
    "def map_for_dict_MariStat(MariStat):\n",
    "  dict_MariStat = {'Other':0, 'Alone':1}\n",
    "  res = dict_MariStat.get(MariStat)\n",
    "  return res\n",
    "\n",
    "def f_VehUsage_Professional(VehUsage):\n",
    "  if VehUsage == 'Professional':\n",
    "    VehUsage_Professional = 1\n",
    "  else:\n",
    "    VehUsage_Professional = 0\n",
    "  return(VehUsage_Professional)\n",
    "\n",
    "def f_VehUsage_Private_trip_to_office(VehUsage):\n",
    "  if VehUsage == 'Private+trip to office':\n",
    "    VehUsage_Private_trip_to_office = 1\n",
    "  else:\n",
    "    VehUsage_Private_trip_to_office = 0\n",
    "  return(VehUsage_Private_trip_to_office)\n",
    "\n",
    "def f_VehUsage_Private(VehUsage):\n",
    "  if VehUsage == 'Private':\n",
    "    VehUsage_Private = 1\n",
    "  else:\n",
    "    VehUsage_Privatel = 0\n",
    "  return(VehUsage_Private)\n",
    "\n",
    "def f_VehUsage_Professional_run(VehUsage):\n",
    "  if VehUsage == 'Professional run':\n",
    "    VehUsage_Professional_run = 1\n",
    "  else:\n",
    "    VehUsage_Professional_run = 0\n",
    "  return(VehUsage_Professional_run)\n",
    "\n",
    "def return_NewH2o_Frame():\n",
    "  columns = [\n",
    "      'LicAge',\n",
    "      'Gender',\n",
    "      'MariStat',\n",
    "      'DrivAge',\n",
    "      'HasKmLimit',\n",
    "      'BonusMalus',\n",
    "      'OutUseNb',\n",
    "      'RiskArea',\n",
    "      'VehUsg_Private',\n",
    "      'VehUsg_Private+trip to office',\n",
    "      'VehUsg_Professional',\n",
    "      'VehUsg_Professional run',\n",
    "      'CSP1',\n",
    "      'CSP2',\n",
    "      'CSP3',\n",
    "      'CSP6',\n",
    "      'CSP7',\n",
    "      'CSP20',\n",
    "      'CSP21',\n",
    "      'CSP22',\n",
    "      'CSP26',\n",
    "      'CSP37',\n",
    "      'CSP40',\n",
    "      'CSP42',\n",
    "      'CSP46',\n",
    "      'CSP47',\n",
    "      'CSP48',\n",
    "      'CSP49',\n",
    "      'CSP50',\n",
    "      'CSP55',\n",
    "      'CSP56',\n",
    "      'CSP57',\n",
    "      'CSP60',\n",
    "      'CSP65',\n",
    "      'CSP66'\n",
    "      ]\n",
    "  return h2o.H2OFrame([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]], column_names = columns)\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)\n",
    "\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def predict3():\n",
    "\n",
    "    try:\n",
    "\n",
    "      json_input = request.json\n",
    "\n",
    "      ID = json_input[\"ID\"]\n",
    "      LicAge = json_input[\"LicAge\"]\n",
    "      Gender = map_for_dict_Gender(json_input[\"Gender\"])\n",
    "      MariStat = map_for_dict_MariStat(json_input[\"MariStat\"])\n",
    "      DrivAge = json_input[\"DrivAge\"]\n",
    "      HasKmLimit = json_input[\"HasKmLimit\"]\n",
    "      BonusMalus = json_input[\"BonusMalus\"]\n",
    "      OutUseNb = json_input[\"OutUseNb\"]\n",
    "      RiskArea = json_input[\"RiskArea\"]\n",
    "      VehUsg_Private = f_VehUsage_Private(json_input[\"VehUsage\"])\n",
    "      VehUsg_Private_trip_to_office = f_VehUsage_Private_trip_to_office(json_input[\"VehUsage\"])\n",
    "      VehUsg_Professional = f_VehUsage_Professional(json_input[\"VehUsage\"])\n",
    "      VehUsg_Professional_run = f_VehUsage_Professional_run(json_input[\"VehUsage\"])\n",
    "      CSP1 = 0\n",
    "      CSP2 = 0\n",
    "      CSP3 = 0\n",
    "      CSP6 = 0\n",
    "      CSP7 = 0\n",
    "      CSP20 = 0\n",
    "      CSP21 = 0\n",
    "      CSP22 = 0\n",
    "      CSP26 = 0\n",
    "      CSP37 = 0\n",
    "      CSP40 = 0\n",
    "      CSP42 = 0\n",
    "      CSP46 = 0\n",
    "      CSP47 = 0\n",
    "      CSP48 = 0\n",
    "      CSP49 = 0\n",
    "      CSP50 = 0\n",
    "      CSP55 = 0\n",
    "      CSP56 = 0\n",
    "      CSP57 = 0\n",
    "      CSP60 = 0\n",
    "      CSP65 = 0\n",
    "      CSP66 = 0\n",
    "\n",
    "      hf = return_NewH2o_Frame()\n",
    "\n",
    "      hf[0, 'LicAge'] = LicAge\n",
    "      hf[0, 'Gender'] = Gender\n",
    "      hf[0, 'MariStat'] = MariStat\n",
    "      hf[0, 'DrivAge'] = DrivAge\n",
    "      hf[0, 'HasKmLimit'] = HasKmLimit\n",
    "      hf[0, 'BonusMalus'] = BonusMalus\n",
    "      hf[0, 'OutUseNb'] = OutUseNb\n",
    "      hf[0, 'RiskArea'] = RiskArea\n",
    "      hf[0, 'VehUsg_Private'] = VehUsg_Private\n",
    "      hf[0, 'VehUsg_Private+trip to office'] = VehUsg_Private_trip_to_office\n",
    "      hf[0, 'VehUsg_Professional'] = VehUsg_Professional\n",
    "      hf[0, 'VehUsg_Professional run'] = VehUsg_Professional_run\n",
    "      hf[0, 'CSP1'] = CSP1\n",
    "      hf[0, 'CSP2'] = CSP2\n",
    "      hf[0, 'CSP3'] = CSP3\n",
    "      hf[0, 'CSP6'] = CSP6\n",
    "      hf[0, 'CSP7'] = CSP7\n",
    "      hf[0, 'CSP20'] = CSP20\n",
    "      hf[0, 'CSP21'] = CSP21\n",
    "      hf[0, 'CSP22'] = CSP22\n",
    "      hf[0, 'CSP26'] = CSP26\n",
    "      hf[0, 'CSP37'] = CSP37\n",
    "      hf[0, 'CSP40'] = CSP40\n",
    "      hf[0, 'CSP42'] = CSP42\n",
    "      hf[0, 'CSP46'] = CSP46\n",
    "      hf[0, 'CSP47'] = CSP47\n",
    "      hf[0, 'CSP48'] = CSP48\n",
    "      hf[0, 'CSP49'] = CSP49\n",
    "      hf[0, 'CSP50'] = CSP50\n",
    "      hf[0, 'CSP55'] = CSP55\n",
    "      hf[0, 'CSP56'] = CSP56\n",
    "      hf[0, 'CSP57'] = CSP57\n",
    "      hf[0, 'CSP60'] = CSP60\n",
    "      hf[0, 'CSP65'] = CSP65\n",
    "      hf[0, 'CSP66'] = CSP66\n",
    "\n",
    "      prediction_Poisson = model_glm_poisson.predict(hf)\n",
    "      value_Poisson  = prediction_Poisson.as_data_frame()['predict'][0]\n",
    "      prediction_Gamma = model_glm_gamma.predict(hf)\n",
    "      value_Gamma  = prediction_Gamma.as_data_frame()['predict'][0]\n",
    "      value_BurningCost = value_Poisson * value_Gamma\n",
    "\n",
    "      return jsonify({'ID':ID, 'value_Poisson':value_Poisson, 'value_Gamma':value_Gamma, 'value_BurningCost':value_BurningCost}) \n",
    "    \n",
    "    except:\n",
    "      \n",
    "      return \"Error\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "response:\n",
    "{\"ID\":1,\"value_BurningCost\":110.82390163199808,\"value_Gamma\":431.58001180103514,\"value_Poisson\":0.25678645581735043}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
